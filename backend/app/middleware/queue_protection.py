"""
ðŸš¨ T-003 Queue DoS Protection Middleware (CVSS 8.6)
Comprehensive protection against queue draining and resource exhaustion attacks.
Implements circuit breaker, queue monitoring, and advanced rate limiting.
"""

import asyncio
import time
from collections import deque
from dataclasses import dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Tuple

from fastapi import Request, status
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware

from ..config.configuration import get_settings
from ..constants import RateLimits
from ..logging.config import get_logger

logger = get_logger(__name__)


class CircuitBreakerState(Enum):
    """Circuit breaker states"""

    CLOSED = "closed"  # Normal operation
    OPEN = "open"  # Circuit is open, rejecting requests
    HALF_OPEN = "half_open"  # Testing if service has recovered


@dataclass
class QueueMetrics:
    """Queue health metrics"""

    current_depth: int
    processing_jobs: int
    failed_jobs_last_hour: int
    average_processing_time: float
    error_rate: float
    timestamp: float


@dataclass
class IPBehavior:
    """IP behavior tracking for advanced DoS detection"""

    request_times: deque
    job_submissions: deque
    burst_violations: int
    last_burst_time: float
    total_jobs_today: int
    last_daily_reset: float
    concurrent_jobs: int
    penalty_until: float


class CircuitBreaker:
    """Circuit breaker for queue protection"""

    def __init__(self):
        self.state = CircuitBreakerState.CLOSED
        self.failure_count = 0
        self.request_count = 0
        self.last_failure_time = 0
        self.next_attempt_time = 0

    def record_success(self):
        """Record successful request"""
        self.failure_count = 0
        self.request_count += 1
        if self.state == CircuitBreakerState.HALF_OPEN:
            self.state = CircuitBreakerState.CLOSED
            logger.info("Circuit breaker: Recovered, switching to CLOSED")

    def record_failure(self):
        """Record failed request"""
        self.failure_count += 1
        self.request_count += 1
        self.last_failure_time = time.time()

        # Check if we should open the circuit
        if (
            self.request_count >= RateLimits.MIN_REQUESTS_FOR_CIRCUIT
            and self.failure_count / self.request_count
            >= RateLimits.ERROR_RATE_THRESHOLD
        ):
            self.state = CircuitBreakerState.OPEN
            self.next_attempt_time = time.time() + RateLimits.CIRCUIT_BREAKER_TIMEOUT
            logger.warning(
                f"Circuit breaker: OPENED due to error rate {self.failure_count}/{self.request_count}"
            )

    def can_request(self) -> bool:
        """Check if request can proceed"""
        now = time.time()

        if self.state == CircuitBreakerState.CLOSED:
            return True
        elif self.state == CircuitBreakerState.OPEN:
            if now >= self.next_attempt_time:
                self.state = CircuitBreakerState.HALF_OPEN
                logger.info("Circuit breaker: Switching to HALF_OPEN for testing")
                return True
            return False
        elif self.state == CircuitBreakerState.HALF_OPEN:
            return True

        return False


class QueueDosProtection:
    """Advanced Queue DoS Protection System"""

    def __init__(self, redis_client=None, bypass_protection_for_tests=False):
        self.redis_client = redis_client
        self.settings = get_settings()
        self.bypass_protection_for_tests = bypass_protection_for_tests

        # Circuit breaker
        self.circuit_breaker = CircuitBreaker()

        # IP behavior tracking
        self.ip_behaviors: Dict[str, IPBehavior] = {}

        # Queue metrics
        self.queue_metrics_history: List[QueueMetrics] = []

        # Cleanup intervals
        self.last_cleanup = time.time()
        self.cleanup_interval = 300  # 5 minutes

        # Endpoints that bypass protection
        self.bypass_endpoints = {
            "/health",
            "/metrics",
            "/docs",
            "/redoc",
            "/openapi.json",
        }

    def get_client_ip(self, request: Request) -> str:
        """Extract client IP with enhanced detection"""
        # Check various headers for real IP
        for header in ["X-Forwarded-For", "X-Real-IP", "CF-Connecting-IP"]:
            value = request.headers.get(header)
            if value:
                # Take first IP for X-Forwarded-For
                return value.split(",")[0].strip()

        return request.client.host if request.client else "unknown"

    def get_or_create_ip_behavior(self, client_ip: str) -> IPBehavior:
        """Get or create IP behavior tracking"""
        if client_ip not in self.ip_behaviors:
            now = time.time()
            self.ip_behaviors[client_ip] = IPBehavior(
                request_times=deque(maxlen=100),
                job_submissions=deque(maxlen=50),
                burst_violations=0,
                last_burst_time=0,
                total_jobs_today=0,
                last_daily_reset=now,
                concurrent_jobs=0,
                penalty_until=0,
            )

        return self.ip_behaviors[client_ip]

    async def get_queue_metrics(self) -> QueueMetrics:
        """Get current queue health metrics"""
        try:
            if not self.redis_client:
                # Fallback metrics when Redis unavailable
                return QueueMetrics(
                    current_depth=0,
                    processing_jobs=0,
                    failed_jobs_last_hour=0,
                    average_processing_time=0.0,
                    error_rate=0.0,
                    timestamp=time.time(),
                )

            # Get queue depth
            queue_depth = (
                await asyncio.to_thread(self.redis_client.llen, "rq:queue:default")
                if hasattr(self.redis_client, "llen")
                else 0
            )

            # Get processing jobs (simplified)
            processing_jobs = queue_depth  # Simplified metric

            # Calculate basic metrics
            metrics = QueueMetrics(
                current_depth=queue_depth,
                processing_jobs=processing_jobs,
                failed_jobs_last_hour=0,  # Simplified
                average_processing_time=30.0,  # Estimated
                error_rate=self.circuit_breaker.failure_count
                / max(self.circuit_breaker.request_count, 1),
                timestamp=time.time(),
            )

            # Store metrics history
            self.queue_metrics_history.append(metrics)
            if len(self.queue_metrics_history) > 100:
                self.queue_metrics_history.pop(0)

            return metrics
        except Exception as e:
            logger.error(f"Error getting queue metrics: {e}")
            return QueueMetrics(
                current_depth=0,
                processing_jobs=0,
                failed_jobs_last_hour=0,
                average_processing_time=0.0,
                error_rate=0.0,
                timestamp=time.time(),
            )

    def check_burst_detection(
        self, ip_behavior: IPBehavior, client_ip: str
    ) -> Tuple[bool, Optional[str]]:
        """Check for request bursts from IP"""
        now = time.time()

        # Skip burst detection for test client when bypass is enabled
        if self.bypass_protection_for_tests and client_ip == "testclient":
            return True, None

        # Check if IP is in penalty period
        if now < ip_behavior.penalty_until:
            return (
                False,
                f"IP in penalty period for {int(ip_behavior.penalty_until - now)} seconds due to burst detection",
            )

        # Add current request time
        ip_behavior.request_times.append(now)

        # Only check burst if we have enough samples
        if len(ip_behavior.request_times) >= RateLimits.MAX_BURST_REQUESTS:
            window_start = ip_behavior.request_times[-RateLimits.MAX_BURST_REQUESTS]
            time_diff = now - window_start

            if time_diff < RateLimits.BURST_DETECTION_WINDOW:
                ip_behavior.burst_violations += 1
                ip_behavior.last_burst_time = now
                ip_behavior.penalty_until = now + (
                    RateLimits.BURST_PENALTY_MINUTES * 60
                )

                logger.warning(
                    f"Burst detected for IP {client_ip}: {RateLimits.MAX_BURST_REQUESTS} requests in {time_diff:.1f}s"
                )
                return (
                    False,
                    f"Burst detected: {RateLimits.MAX_BURST_REQUESTS} requests in {int(time_diff)} seconds",
                )

        return True, None

    def check_job_limits(
        self, ip_behavior: IPBehavior, client_ip: str, is_job_request: bool
    ) -> Tuple[bool, Optional[str]]:
        """Check job submission limits"""
        now = time.time()

        # Skip job limits for test client when bypass is enabled
        if self.bypass_protection_for_tests and client_ip == "testclient":
            return True, None

        # Reset daily counters if needed
        if now - ip_behavior.last_daily_reset >= RateLimits.DAY_WINDOW:
            ip_behavior.total_jobs_today = 0
            ip_behavior.last_daily_reset = now

        # Only apply limits for job creation requests
        if is_job_request:
            # Check concurrent job limit
            if ip_behavior.concurrent_jobs >= RateLimits.CONCURRENT_JOBS_PER_IP:
                return (
                    False,
                    f"Concurrent job limit exceeded: {ip_behavior.concurrent_jobs}/{RateLimits.CONCURRENT_JOBS_PER_IP}",
                )

            # Check daily job limit
            if ip_behavior.total_jobs_today >= RateLimits.JOBS_PER_DAY:
                return (
                    False,
                    f"Daily job limit exceeded: {ip_behavior.total_jobs_today}/{RateLimits.JOBS_PER_DAY}",
                )

            # Check hourly job limit
            recent_jobs = [
                t
                for t in ip_behavior.job_submissions
                if now - t <= RateLimits.HOUR_WINDOW
            ]
            if len(recent_jobs) >= RateLimits.JOBS_PER_HOUR:
                return (
                    False,
                    f"Hourly job limit exceeded: {len(recent_jobs)}/{RateLimits.JOBS_PER_HOUR}",
                )

        return True, None

    async def check_queue_health(self) -> Tuple[bool, Optional[str]]:
        """Check overall queue health"""
        metrics = await self.get_queue_metrics()

        # Skip health checks for test environment
        if self.bypass_protection_for_tests:
            return True, None

        # Check queue depth
        if metrics.current_depth > RateLimits.MAX_QUEUE_DEPTH:
            return False, f"Queue depth limit exceeded: {metrics.current_depth}"

        # Check error rate
        if metrics.error_rate > RateLimits.ERROR_RATE_THRESHOLD:
            return False, f"High error rate detected: {metrics.error_rate:.2%}"

        return True, None

    async def validate_request(
        self, request: Request
    ) -> Tuple[bool, Optional[Dict[str, Any]]]:
        """Validate request against all protection mechanisms"""
        client_ip = self.get_client_ip(request)

        # Bypass all protection for test client when enabled
        if self.bypass_protection_for_tests and client_ip == "testclient":
            return True, None

        # Bypass protection for certain endpoints
        if request.url.path in self.bypass_endpoints:
            return True, None

        # Clean up old data periodically
        now = time.time()
        if now - self.last_cleanup > self.cleanup_interval:
            await self.cleanup_old_data()
            self.last_cleanup = now

        # Get IP behavior
        ip_behavior = self.get_or_create_ip_behavior(client_ip)

        # Check if circuit breaker allows request
        if not self.circuit_breaker.can_request():
            return False, {
                "detail": "Service temporarily unavailable due to circuit breaker",
                "status_code": status.HTTP_503_SERVICE_UNAVAILABLE,
            }

        # Check for request bursts
        can_proceed, burst_error = self.check_burst_detection(ip_behavior, client_ip)
        if not can_proceed:
            return False, {
                "detail": burst_error,
                "status_code": status.HTTP_429_TOO_MANY_REQUESTS,
            }

        # Check job limits
        is_job_request = request.url.path.endswith("/jobs") and request.method == "POST"
        can_proceed, limit_error = self.check_job_limits(
            ip_behavior, client_ip, is_job_request
        )
        if not can_proceed:
            return False, {
                "detail": limit_error,
                "status_code": status.HTTP_429_TOO_MANY_REQUESTS,
            }

        # Check queue health
        can_proceed, health_error = await self.check_queue_health()
        if not can_proceed:
            return False, {
                "detail": health_error,
                "status_code": status.HTTP_503_SERVICE_UNAVAILABLE,
            }

        # Track successful validation
        if is_job_request:
            ip_behavior.job_submissions.append(now)
            ip_behavior.total_jobs_today += 1
            ip_behavior.concurrent_jobs += 1

        return True, None

    def record_job_completion(self, client_ip: str, success: bool):
        """Record job completion for IP"""
        if client_ip in self.ip_behaviors:
            ip_behavior = self.ip_behaviors[client_ip]
            ip_behavior.concurrent_jobs = max(0, ip_behavior.concurrent_jobs - 1)

            if success:
                self.circuit_breaker.record_success()
            else:
                self.circuit_breaker.record_failure()

    async def cleanup_old_data(self):
        """Clean up old tracking data"""
        now = time.time()
        expired_ips = []

        for ip, behavior in self.ip_behaviors.items():
            # Remove IPs with no recent activity
            if (
                not behavior.request_times
                or now - behavior.request_times[-1] > self.cleanup_interval
            ):
                expired_ips.append(ip)

        for ip in expired_ips:
            del self.ip_behaviors[ip]

        # Trim metrics history
        while (
            self.queue_metrics_history
            and now - self.queue_metrics_history[0].timestamp > self.cleanup_interval
        ):
            self.queue_metrics_history.pop(0)


class QueueDosProtectionMiddleware(BaseHTTPMiddleware):
    """Middleware for queue DoS protection"""

    def __init__(self, app, redis_client=None, bypass_protection_for_tests=False):
        super().__init__(app)
        self.protection = QueueDosProtection(redis_client, bypass_protection_for_tests)

    async def dispatch(self, request: Request, call_next):
        """Handle request with DoS protection"""
        # Validate request
        can_proceed, error_response = await self.protection.validate_request(request)
        if not can_proceed:
            return JSONResponse(
                content={"detail": error_response["detail"]},
                status_code=error_response["status_code"],
            )

        # Process request
        try:
            response = await call_next(request)

            # Record successful job completion
            if request.url.path.endswith("/jobs") and request.method == "POST":
                self.protection.record_job_completion(
                    self.protection.get_client_ip(request),
                    response.status_code in (200, 201, 202),
                )

            return response
        except Exception as e:
            # Record failed job completion
            if request.url.path.endswith("/jobs") and request.method == "POST":
                self.protection.record_job_completion(
                    self.protection.get_client_ip(request), False
                )
            raise


async def get_queue_protection_status(protection: QueueDosProtection) -> Dict[str, Any]:
    """Get current protection status for monitoring"""
    metrics = await protection.get_queue_metrics()
    return {
        "circuit_breaker_state": protection.circuit_breaker.state.value,
        "queue_depth": metrics.current_depth,
        "error_rate": metrics.error_rate,
        "tracked_ips": len(protection.ip_behaviors),
    }
